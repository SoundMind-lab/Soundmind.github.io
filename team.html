<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Our Team - Soundmind Neurovision Innovation Lab</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Our Team</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="team.html">Team</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>

    <section>
        <h2>Meet Our Team</h2>
      
      
    <div class="team">
        <!-- Example PhD Student Entry -->
        <div class="team-member">
            <img src="ShrutiKshirsagar.jpg" alt="Dr. Shruti Kshirsagar">
            <div class="bio">
                <div class="name">Dr. Shruti Rajendra Kshirsagar (Assistant Professor)</div>
                <div class="position">Assistant Professor</div>
                <p>Dr. Shruti Rajendra Kshirsagar is an Assistant Professor and graduate coordinator for the MS in data science program at the School of Computing at Wichita State University. She specializes in Data Science, Deep Learning, Machine Learning, and Speech Signal Processing. Dr. Kshirsagar's research interests extend to Affective Computing, Healthcare and AI, Medical Image Processing, Assistive Technology, human-machine interface, Artificial Intelligence, and Sound Recognition. 

She earned her PhD in Telecommunications from Institut National de la recherche scientifique (INRS) in Montreal, Canada, where she specialized in Speech & Deep Learning, and data science. She holds a Master's and Bachelor's degree in Electronics & Telecommunication Engineering from the University of Mumbai, with a focus on Communication, statistics, and Signal Processing.

At Wichita State University, Dr. Kshirsagar is responsible for teaching and mentoring graduate students, developing and implementing advanced curricula in Deep Learning and Machine Learning. She has significant industry experience, having worked as an Audio R&D Scientist at EERS Global Technologies Inc. in Montreal and as a Machine Learning for Audio Analytics Intern at Robert Bosch Inc. in Mississauga, Canada.

Dr. Kshirsagar's exemplary contributions to research have been recognized with several prestigious awards, including the Best Doctoral Thesis Award from INRS. She has also been awarded multiple research grants.

Her professional memberships include IEEE Signal Processing Society, IEEE Young Professionals, IEEE Women in Engineering, and the International Speech Communication Association (ISCA), among others. Dr. Kshirsagar's work is widely published in renowned journals and conferences, reflecting her commitment to advancing the fields of Affective computing, deep learning, and signal processing.</p>
            </div>
        </div>

        <!-- Add more team members below -->
        <!-- Example 2 -->
        <div class="team-member">
            <img src="ShrutiKshirsagar.jpg" alt="Another Student Name">
            <div class="bio">
                <div class="name">Another Student Name</div>
                <div class="position">PhD Student</div>
                <p>Short bio about another PhD student.</p>
            </div>
        </div>

        <!-- Additional team members can be added similarly -->
    </div>

        <ul>
 <li>Salari Elmira - Large Language Modelling Researcher</li>
              
            <li>Fatemeh Karji - Brain Tumor Segmentation Researcher</li>
            <li>Sriram Srinivasan - Speech Emotion Recognition Researcher</li>
            <li>Parupati Bharath Chandra Reddy - Audio Event Detection Researcher</li>
            <li>Leonidah Chepkoech - Medical Image Segmentation Researcher</li>
            <li>Mark Angelo Ronaldo - Medical Image Segmentation Researcher</li>
           
        </ul>
    </section>

    <footer>
        <p>&copy; 2024 Soundmind Neurovision Innovation Lab. All rights reserved.</p>
    </footer>
</body>
</html>
